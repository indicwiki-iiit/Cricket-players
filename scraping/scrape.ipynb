{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dUl-pR0TZaN-"
   },
   "outputs": [],
   "source": [
    "#Run any one cell to select a certain url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GcKCEpUGuwZH",
    "outputId": "fcf862f4-13a1-4700-dc34-9bdc3bd2a59b"
   },
   "outputs": [],
   "source": [
    "!sudo apt-get install chromium-chromedriver\n",
    "!sudo apt-get update\n",
    "!sudo apt-get install chromium-chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iQShvi2kawzd",
    "outputId": "dbfcc45b-2e51-4366-a067-569866356467"
   },
   "outputs": [],
   "source": [
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "password = getpass.getpass()\n",
    "command = \"sudo -S apt-get install chromium-chromedriver\"\n",
    "os.system('echo %s | %s' % (password, command))\n",
    "command = \"sudo -S apt-get update\"\n",
    "os.system('echo %s | %s' % (password, command))\n",
    "command = \"sudo -S apt-get install chromium-chromedriver\"\n",
    "os.system('echo %s | %s' % (password, command))\n",
    "\n",
    "# If facing issues with the default firefox driver for webscraping using selenium , run the below code\n",
    "# !sudo apt-get install chromium-chromedriver\n",
    "# !sudo apt-get update\n",
    "# !sudo apt-get install chromium-chromedriver\n",
    "!pip install selenium\n",
    "# Here the chrome driver is being used , hence replace firefox with Chrome driver as given below\n",
    "!pip install webdriver-manager\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "wd = webdriver.Chrome(ChromeDriverManager().install(), options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k_vsk5BDtuAO"
   },
   "outputs": [],
   "source": [
    "#Alphabetical parse url\n",
    "#url = \"https://www.espncricinfo.com/ci/content/player/country.html?country=6;alpha=A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y4UqagRqtuAS"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bf\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "# driver = webdriver.Firefox()\n",
    "# driver = webdriver.Chrome(options=options)\n",
    "driver = wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zMcBcnhbjwX4"
   },
   "outputs": [],
   "source": [
    "def evaluate(html):\n",
    "  select_divs = html.find_all('div',class_=\"card overflow-hidden mb-3\")\n",
    "  exist = 0\n",
    "  location = 0\n",
    "  for i in range(len(select_divs)):\n",
    "    check = \"\"\n",
    "    try:\n",
    "      check = select_divs[i].find('p',class_=\"benton-bold pl-3 pt-4 pb-3 m-0 player-card-header\").text\n",
    "    except:\n",
    "      k = 1\n",
    "    if(check == \"Career Averages\"):\n",
    "      exist = 1\n",
    "      location = i\n",
    "      break\n",
    "  try:\n",
    "    position = select_divs[location]\n",
    "  except:\n",
    "    position = \"\"\n",
    "    exist = 0\n",
    "  return exist,position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZM0_9SZXVLVk"
   },
   "outputs": [],
   "source": [
    "def get_player_image():\n",
    "    # For fixing installation errors on linux: `sudo apt install firefox-geckodriver`\n",
    "    global driver\n",
    "    images = driver.find_elements_by_tag_name('img')\n",
    "    images = [image for image in images if \"player-card__face\" in image.get_attribute(\"class\")]\n",
    "    if len(images) < 1:\n",
    "        return [\"image\"], [\"\"]\n",
    "    # print(images[0].get_attribute(\"src\"))\n",
    "    return [\"image\"], [images[0].get_attribute(\"src\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SxY2A7SCVLVk"
   },
   "outputs": [],
   "source": [
    "# Get trophy info\n",
    "def get_major_trophies_information(major_trophies_soup):\n",
    "    major_trophies_results = {}\n",
    "    all_h5_tags = major_trophies_soup.find_all('h5', class_=\"border-bottom-gray-300 m-0 pl-3 pb-2 table-header\")\n",
    "    if all_h5_tags is None:\n",
    "        return None\n",
    "    try:\n",
    "        required_h5_tag = all_h5_tags[0]\n",
    "    except:\n",
    "        print('-'*50)\n",
    "        print(all_h5_tags)\n",
    "        print('-'*50)\n",
    "    for h5_tag in all_h5_tags:\n",
    "        if str(h5_tag.text).strip() == \"In Major Trophies\":\n",
    "            required_h5_tag = h5_tag\n",
    "            break\n",
    "    if str(required_h5_tag.text).strip() != \"In Major Trophies\":\n",
    "        return [\"Major trophies\"], [[major_trophies_results]]\n",
    "    major_trophies_table_head = required_h5_tag.findNext('thead')\n",
    "    major_trophies_table_headings = major_trophies_table_head.find_all('th')\n",
    "    major_trophies_table_headings_count = 0\n",
    "    major_trophies_headings_list = []\n",
    "    for table_heading in major_trophies_table_headings:\n",
    "        major_trophies_headings_list.append(table_heading.text)\n",
    "    major_trophies_table_headings_count = len(major_trophies_headings_list)\n",
    "    # print('Major Trophies table Head count', major_trophies_table_headings_count)\n",
    "    current_title = \"HOME\"\n",
    "    major_trophies_table_body = major_trophies_table_head.findNext('tbody')\n",
    "    major_trophies_table_data = major_trophies_table_body.find_all('td')\n",
    "    t = 0\n",
    "    for table_data in major_trophies_table_data:\n",
    "        attribute_number = t % major_trophies_table_headings_count\n",
    "        if(attribute_number != 0):\n",
    "            major_trophies_results[current_title][major_trophies_headings_list[attribute_number]] = table_data.text\n",
    "        else:\n",
    "            current_title = table_data.text\n",
    "            major_trophies_results[current_title] = {}\n",
    "        t += 1\n",
    "    # print(major_trophies_results)\n",
    "    return [\"Major trophies\"], [[major_trophies_results]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nLrgeH90VLVl"
   },
   "outputs": [],
   "source": [
    "# Statistical analysis - Home, Away stats and function call to trophy info\n",
    "def get_statistical_analysis_and_trophy_info_and_image(req):\n",
    "    analysis_labels = []\n",
    "    analysis_results = []\n",
    "    analysis_url = req.url + \"/bowling-batting-stats\"\n",
    "    #analysis_url = \"https://www.espncricinfo.com/player/virat-kohli-253802/bowling-batting-stats\"\n",
    "    \n",
    "    # selecting dropdown option\n",
    "    global driver\n",
    "    try:\n",
    "        driver.get(analysis_url)\n",
    "    except:\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install(), options=options)\n",
    "        driver.get(analysis_url)\n",
    "    # loading page\n",
    "    time.sleep(2)\n",
    "    dropdowns = driver.find_elements_by_class_name('dropdown-container')\n",
    "    for dropdown in dropdowns:\n",
    "        is_format_dropdown = str(dropdown.find_elements_by_tag_name('button')[0].text).strip() in [\"Test\", \"ODI\", \"T20I\", \"Test+ODI+T20I\"]\n",
    "        is_role_dropdown = str(dropdown.find_elements_by_tag_name('button')[0].text).strip() in [\"Batting\", \"Bowling\", \"Fielding\", \"Allround\"]\n",
    "        if (not is_format_dropdown) and (not is_role_dropdown):\n",
    "            continue\n",
    "        required_span_text = \"Test+ODI+T20I\"\n",
    "        if is_role_dropdown:\n",
    "            required_span_text = \"Allround\"\n",
    "        dropdown.find_elements_by_tag_name('button')[0].click()\n",
    "        all_list_items = dropdown.find_elements_by_tag_name('li')\n",
    "        for list_item in all_list_items:\n",
    "            span_text = list_item.find_elements_by_tag_name('span')[0].text\n",
    "            if span_text == required_span_text:\n",
    "                list_item.click()\n",
    "                break\n",
    "    # waiting for changes to load\n",
    "    time.sleep(2)\n",
    "    analysis_page = driver.page_source\n",
    "    analysis_soup = bf(analysis_page, \"html.parser\")\n",
    "    \n",
    "    all_h5_tags = analysis_soup.find_all('h5', class_=\"border-bottom-gray-300 m-0 pl-3 pb-2 table-header\")\n",
    "    # print(all_h5_tags)\n",
    "    if len(all_h5_tags) is not 0:\n",
    "      try:\n",
    "          required_h5_tag = all_h5_tags[0]\n",
    "      except:\n",
    "          print('-'*50)\n",
    "          print(all_h5_tags)\n",
    "          print('-'*50)\n",
    "      for h5_tag in all_h5_tags:\n",
    "          if str(h5_tag.text).strip() == \"Home vs Away\":\n",
    "              required_h5_tag = h5_tag\n",
    "              break\n",
    "      if str(required_h5_tag.text).strip() != \"Home vs Away\":\n",
    "          return get_major_trophies_information(analysis_soup)\n",
    "      analysis_table_head = required_h5_tag.findNext('thead')\n",
    "      analysis_table_headings = analysis_table_head.find_all('th')\n",
    "      analysis_table_headings_count = 0\n",
    "      analysis_table_headings_list = []\n",
    "      for table_heading in analysis_table_headings:\n",
    "          analysis_table_headings_list.append(table_heading.text)\n",
    "      analysis_table_headings_count = len(analysis_table_headings_list)\n",
    "      # print('Analysis table Head count', analysis_table_headings_count)\n",
    "      current_title = \"HOME\"\n",
    "      analysis_table_body = analysis_table_head.findNext('tbody')\n",
    "      analysis_table_data = analysis_table_body.find_all('td')\n",
    "      t = 0\n",
    "      for table_data in analysis_table_data:\n",
    "          attribute_number = t % analysis_table_headings_count\n",
    "          if(attribute_number != 0):\n",
    "              analysis_results.append(table_data.text)\n",
    "              analysis_labels.append(current_title + \"_\" + analysis_table_headings_list[attribute_number])\n",
    "          else:\n",
    "              current_title = table_data.text.upper()\n",
    "          t += 1\n",
    "      trophy_label, trophy_result = get_major_trophies_information(analysis_soup)\n",
    "      image_label, image_result = get_player_image()\n",
    "    else:\n",
    "      return [] , []\n",
    "    # for i in range(len(analysis_labels)):\n",
    "    #     print(f'{analysis_labels[i]} : {analysis_results[i]}')\n",
    "\n",
    "    return analysis_labels + trophy_label + image_label, analysis_results + trophy_result + image_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4TAwtcBXVLVl"
   },
   "outputs": [],
   "source": [
    "def find_relations(Relations):\n",
    "    relations_container = Relations.find_next('div')\n",
    "    individual_relations = relations_container.find_all('span')\n",
    "    total_relations = list()\n",
    "    for i in range(len(individual_relations)):\n",
    "        name = individual_relations[i].find('h5').text\n",
    "        bond = individual_relations[i].find('p').text\n",
    "        total_relations.append([name,bond])\n",
    "    return total_relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7A_yiQzdtuAU"
   },
   "outputs": [],
   "source": [
    "#Get relevant information related to a player using each player's url\n",
    "def load(req,final_list_players,ind,u,debut_url):\n",
    "    lab = list()\n",
    "    result = list()\n",
    "    soup = bf(req.text,\"html.parser\")\n",
    "    all_player_urls = [req.url]\n",
    "    print(soup.title)\n",
    "    search_tag_container = soup.find_all('h5',class_='player-card-description gray-900')\n",
    "    count = 0\n",
    "    for job_elem in search_tag_container:\n",
    "        result.append(job_elem.text)\n",
    "        count+=1\n",
    "    search_tag_container = soup.find_all('p',class_=\"text-uppercase gray-700 mb-0 pb-0-5 player-card-heading\")\n",
    "    player_gender = \"Male\"\n",
    "    for job_elem in search_tag_container:\n",
    "        lab.append(job_elem.text)\n",
    "    player_role = \"xyz\"\n",
    "    for i in range(len(lab)):\n",
    "        if \"role\" in lab[i].lower():\n",
    "            player_role = result[i].lower()\n",
    "            break\n",
    "    ##################################\n",
    "    valid, bat_bowl_soup = evaluate(soup)\n",
    "    if valid != 1:\n",
    "        return\n",
    "    search_tag_container = bat_bowl_soup.findAll('thead')\n",
    "    match_averages = []\n",
    "    runs_scored_as_batsman = 0\n",
    "    balls_bowled_as_bowler = 0\n",
    "    for m in range(len(search_tag_container)):\n",
    "        actual_heading = search_tag_container[m].findPrevious('h5').text\n",
    "        current_string = \"_\"\n",
    "        if \"Bowling\" in actual_heading:\n",
    "            current_string = \"Bowling_\"\n",
    "        elif \"Batting\" in actual_heading:\n",
    "            current_string = \"Batting_\"\n",
    "        else:\n",
    "            continue\n",
    "        match_records = {}\n",
    "        tag_content = search_tag_container[m].find_all('th')\n",
    "        head = 0\n",
    "        table_labels = list()\n",
    "        table_labels_1 =list()\n",
    "        for job_elem in tag_content:\n",
    "            table_labels.append(job_elem.text)\n",
    "            head += 1\n",
    "        # print('Head count',head)\n",
    "\n",
    "        tag_content = search_tag_container[m].findNext('tbody').find_all('td')\n",
    "        track_head_label = 0\n",
    "        current_format = \"\"\n",
    "        for job_elem in tag_content:\n",
    "            attribute_number = track_head_label % head\n",
    "            if(attribute_number != 0):\n",
    "                result.append(job_elem.text)\n",
    "                label_text = table_labels[attribute_number]\n",
    "                lab.append(current_string + current_format + '_' + label_text)\n",
    "                count += 1\n",
    "                if label_text.lower() == \"mat\":\n",
    "                    match_records[current_format.lower()] = job_elem.text\n",
    "                if current_string == \"Batting_\" and label_text.lower() == \"runs\":\n",
    "                    try:\n",
    "                        runs_scored_as_batsman += (int(job_elem.text))\n",
    "                    except:\n",
    "                        pass\n",
    "                elif current_string == \"Bowling_\" and label_text.lower() == \"balls\":\n",
    "                    try:\n",
    "                        balls_bowled_as_bowler += (int(job_elem.text))\n",
    "                    except:\n",
    "                        pass\n",
    "            else:\n",
    "                current_format = job_elem.text\n",
    "                if current_format[0] == 'W':\n",
    "                    player_gender = \"Female\"\n",
    "                    if current_format == \"WTEST\":\n",
    "                        current_format = \"Test\"\n",
    "                    else:\n",
    "                        current_format = current_format[1:]\n",
    "            track_head_label += 1\n",
    "        match_averages.append(match_records)\n",
    "    lab.append(\"Gender\")\n",
    "    result.append(player_gender)\n",
    "    if(len(match_averages) != 2):\n",
    "        return\n",
    "    internationals = 0\n",
    "    non_internationals = 0\n",
    "    for key in match_averages[0]:\n",
    "        if key in match_averages[1]:\n",
    "            if key == \"test\" or key == \"odi\" or key == \"t20i\":\n",
    "                try:\n",
    "                    internationals += max(int(match_averages[0][key]), int(match_averages[1][key]))\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                try:\n",
    "                    non_internationals += max(int(match_averages[0][key]), int(match_averages[1][key]))\n",
    "                except:\n",
    "                    pass\n",
    "    if internationals == 0 and non_internationals < 15:\n",
    "        return\n",
    "    if runs_scored_as_batsman < 50 and balls_bowled_as_bowler < 50:\n",
    "        return\n",
    "    if (\"bat\" in player_role or \"keep\" in player_role) and runs_scored_as_batsman < 100:\n",
    "        return\n",
    "    if \"bowl\" in player_role and balls_bowled_as_bowler < 100:\n",
    "        return\n",
    "    if \"round\" in player_role and (runs_scored_as_batsman < 50 or balls_bowled_as_bowler < 50):\n",
    "        return\n",
    "    ####################################\n",
    "    individual_player_id = str(req.url).split('-')[-1]\n",
    "    lab.append(\"Cricinfo_id\")\n",
    "    result.append(individual_player_id)\n",
    "    ####################################\n",
    "    Relations = soup.find('p',class_=\"text-uppercase gray-700 mb-0 player-card-heading text-uppercase\")\n",
    "    #relation_players = soup.find('p',class_=\"player-card-description player-description-link gray-900 m-0 player-link\")\n",
    "    if(Relations != None):\n",
    "        if(Relations.text.lower()=='relations' or Relations.text.lower()=='relation'):\n",
    "            lab.append(\"Relations\")\n",
    "            all_relations = find_relations(Relations)\n",
    "            result.append([all_relations])\n",
    "    ######################################\n",
    "    rec = extra(u)\n",
    "    lab.append(\"Records\")\n",
    "    result.append([rec])\n",
    "    if len(rec) > 0:\n",
    "        all_player_urls.append(u)\n",
    "    # print(result)\n",
    "    ##########################################\n",
    "    records_format , records_data = format_records(u)\n",
    "    for iter in range(len(records_format)):\n",
    "      lab.append(records_format[iter])\n",
    "      result.append([records_data[iter]])\n",
    "    ###########################################\n",
    "    matches = debut(debut_url)\n",
    "    if len(matches) > 0:\n",
    "        all_player_urls.append(debut_url)\n",
    "    current_match_format = \"\"\n",
    "    for match_detail in matches:\n",
    "        match_detail = str(match_detail)\n",
    "        if match_detail.startswith(\"Last\"):\n",
    "            lab.append(current_match_format + \"_\" + \"last_appearance\")\n",
    "            result.append(match_detail[5:])\n",
    "        elif match_detail.startswith(\"Debut\"):\n",
    "            lab.append(current_match_format + \"_\" + \"debut\")\n",
    "            result.append(match_detail[6:])\n",
    "        else:\n",
    "            current_match_format = match_detail\n",
    "            if current_match_format[0] == 'W':\n",
    "                if current_match_format == \"WTEST Matches\":\n",
    "                    current_match_format = \"Test Matches\"\n",
    "                else:\n",
    "                    current_match_format = current_match_format[1:]\n",
    "    ##########################################\n",
    "    lab.append(\"Teams\")\n",
    "    team_data = teams_data(soup)\n",
    "    result.append([team_data])\n",
    "    ###########################################\n",
    "    info_labels, info_results = get_statistical_analysis_and_trophy_info_and_image(req)\n",
    "    lab = lab + info_labels\n",
    "    result = result + info_results\n",
    "    if len(info_results) > 0:\n",
    "        all_player_urls.append(req.url + \"/bowling-batting-stats\")\n",
    "    ###########################################\n",
    "    lab.append(\"References\")\n",
    "    result.append([all_player_urls])\n",
    "    ####################################\n",
    "    career_span_tag = soup.find('div', class_=\"intl_career-desktop\")\n",
    "    try:\n",
    "      career_span_tag_text = career_span_tag.findNext('p').text\n",
    "    except:\n",
    "      career_span_tag_text = \"\"\n",
    "    if len(career_span_tag_text) > 0:\n",
    "        career_span_info = \"\"\n",
    "        start_index = 0\n",
    "        for i in range(len(career_span_tag_text)):\n",
    "            if career_span_tag_text[i] == '1' or career_span_tag_text[i] == '2':\n",
    "                start_index = i\n",
    "                break\n",
    "        career_span_tag_text = career_span_tag_text[start_index:]\n",
    "        result.append(career_span_tag_text)\n",
    "        lab.append(\"career_span\")\n",
    "    ###########################################\n",
    "    search_tag_container = soup.find('div',class_=\"player-card__details\")\n",
    "    player_name = search_tag_container.find(\"h2\").text\n",
    "    country = search_tag_container.find(\"span\",class_=\"player-card__country-name\").text\n",
    "    #player_type = search_tag_container.find(\"div\",class_=\"player-card__player-type\")\n",
    "    l_label = [\"Player_Name\",\"Nationality\"]\n",
    "    l = [player_name,country]\n",
    "    result = result + l\n",
    "    lab = lab + l_label\n",
    "    ##########################\n",
    "    \n",
    "    print(f'Labels = {len(lab)}, Results = {len(result)}, count = {count}')\n",
    "    # print(lab)\n",
    "    # print(result)\n",
    "    lo = dict(zip(lab,result))\n",
    "    # print(lo)\n",
    "    lp = pd.DataFrame(lo,index=None)\n",
    "    # print(lp)\n",
    "    final_list_players.append(lp)\n",
    "    # print('count',count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tNzOA_ZttuAV"
   },
   "outputs": [],
   "source": [
    "#Get individual player's \"Records\" information.\n",
    "import re\n",
    "def extra(l):\n",
    "    re = requests.get(l)\n",
    "    time.sleep(2)\n",
    "    so = bf(re.text,\"html.parser\")\n",
    "    res1 = so.find_all('div',class_='col-14 d-flex flex-row')\n",
    "    res = so.find_all('div',class_='row bg-gray-100 class-record-row-p d-flex align-items-center')\n",
    "    #print(res1)\n",
    "    url_list = list()\n",
    "    for i in range(len(res1)):\n",
    "\n",
    "        pre = res1[i].find_all('h1')\n",
    "        loi = res1[i].find_all('p',class_='record-class-title m-0')\n",
    "        #print(loi)    \n",
    "        for j in range(len(pre)):\n",
    "            #print(pre[j].text)\n",
    "            #print(loi[j].text)\n",
    "            url_list.append(str(pre[j].text)  +str(\" \") + str(loi[j].text))\n",
    "    return url_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gjnpshJ-VSLr"
   },
   "outputs": [],
   "source": [
    "\n",
    "def format_records(url):\n",
    "  req = requests.get(url)\n",
    "  soup = bf(req.text,\"html.parser\")\n",
    "  record_sections = soup.find_all('div',class_=\"card content-block\")\n",
    "  required = ['Test Records','ODI Records','T20I Records']\n",
    "  available_labels = list()\n",
    "  labels_data = list()\n",
    "  count = -1\n",
    "  for i in range(len(record_sections)):\n",
    "    name = record_sections[i].find('h5',class_=\"m-0\")\n",
    "    if(name.text in required):\n",
    "      available_labels.append(name.text)\n",
    "      labels_data.append([])\n",
    "      count +=1\n",
    "      individual_block_record = record_sections[i].find_all('a',class_=\"gray-900 benton-normal d-block\")\n",
    "      for i in range(len(individual_block_record)):\n",
    "        try:\n",
    "          a = individual_block_record[i].find('span',class_=\"m-0 benton-bold gray-1000 pr-3\").text\n",
    "          b = individual_block_record[i].find('span',class_=\"list-record-title\").text\n",
    "          c = individual_block_record[i].find('span',class_=\"m-0 ml-1 gray-600\").text\n",
    "          labels_data[count].append(str(a)+str(\" \")+str(b)+str(\" \")+str(c))\n",
    "        except:\n",
    "          no = 1\n",
    "  return available_labels , labels_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rFMqUqH6ON_2"
   },
   "outputs": [],
   "source": [
    "def teams_data(so):\n",
    "  teams = []\n",
    "  loi = so.find_all('h5',class_='m-0 ml-2 link-border-bottom player-description-link')\n",
    "  for i in range(len(loi)):\n",
    "    teams.append(loi[i].text)\n",
    "  return teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Ho2v5lYXUjZ"
   },
   "outputs": [],
   "source": [
    "def debut(link):\n",
    "  player_match = list()\n",
    "  url = link\n",
    "  request = requests.get(url)\n",
    "  soup = bf(request.text,\"html.parser\")\n",
    "  search_tag_container = soup.find_all('div',{'id':'debut-last-matches'})\n",
    "  cp_jo = search_tag_container\n",
    "  if(len(search_tag_container) != 0):\n",
    "    total = cp_jo[0].find_all('div',class_=\"\")\n",
    "    for i in range(len(total)):\n",
    "      p =total[i]\n",
    "      a= p.find('h5',{'class':\"benton-bold player-matches-subtitle d-flex justify-content-between align-items-center player_matches-dropdown m-0\"})\n",
    "      k = total[i].find_all('span',class_=\"match-event-row-debut-last white-space-nowrap\")\n",
    "      search_tag_container = total[i].find_all('span',{\"class\": \"player-match-link\"})\n",
    "      new = total[i].find_all('div',{\"class\":\"col-12 player-match-event-cell white-space-nowrap\"})\n",
    "      #print(a)\n",
    "      #print(k[0])\n",
    "      #print(new)\n",
    "      try:\n",
    "        l =a.span.decompose()\n",
    "      except:\n",
    "        player_match.append(a.text)\n",
    "        #print(a.text)\n",
    "      else:\n",
    "        player_match.append(a.text)\n",
    "        #print(a.text)\n",
    "      for j in range(len(k)):\n",
    "        try:\n",
    "          temp = search_tag_container[j].text\n",
    "        except:\n",
    "          temp = new[j].text\n",
    "        append = k[j].text + str(\" \") + temp\n",
    "        player_match.append(append)\n",
    "        #print(k[j].text,end=\" \")\n",
    "        #print(search_tag_container[j].text)\n",
    "  return player_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 740
    },
    "id": "B9c0G1FctuAW",
    "outputId": "c319cb75-b2a9-4258-9df2-4a6968e99cee"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "final_list_players = list()\n",
    "for country_id in range(1,2):\n",
    "  #Country based parse url\n",
    "  for letter in range(65,91):\n",
    "    url = \"https://www.espncricinfo.com/ci/content/player/country.html?country=\"+str(country_id)+\";alpha=\"+str(chr(letter))\n",
    "    req = requests.get(url)\n",
    "    # print(url)\n",
    "    soup = bf(req.text,\"html.parser\")\n",
    "    #Fetch total urls of players belonging to a country\n",
    "    #country_name = soup.find('span',{'id':'ciShowCountry'})\n",
    "    country_name = soup.find('div',{\"class\":\"icc-home\"})\n",
    "\n",
    "    print(\"-------------------------------------------------\")\n",
    "    print(country_name.text)\n",
    "    print(\"-------------------------------------------------\")\n",
    "    search_tag_container = soup.find_all('td')\n",
    "    u = list()\n",
    "    for job_elem in search_tag_container:\n",
    "        u.append(job_elem.find('a'))\n",
    "        #result.append(job_elem.text)\n",
    "    l = set(u)\n",
    "    l = list(l)\n",
    "    for i in range(len(l)):\n",
    "        u = \"https://www.espncricinfo.com\"\n",
    "        if l[i] is None:\n",
    "            continue\n",
    "        if not l[i].has_attr(\"href\"):\n",
    "            continue\n",
    "        rl = l[i][\"href\"]\n",
    "        link = u+rl\n",
    "        print(link)\n",
    "        #link = \"https://www.espncricinfo.com/player/virat-kohli-253802\"\n",
    "        req = requests.get(link)\n",
    "        time.sleep(2)\n",
    "        print('player-',i,end=\" \")\n",
    "        ind = len(final_list_players)\n",
    "        record_url = req.url+str(\"/tests-odi-t20-records\")\n",
    "        debut_url = req.url+str(\"/matches\")\n",
    "        #debut(debut_url)\n",
    "        load(req,final_list_players,ind,record_url,debut_url)\n",
    "        #print(record_url)\n",
    "        #jk = extra(record_url)\n",
    "        #print(jk)\n",
    "    try:\n",
    "      driver.close()\n",
    "    except:\n",
    "      no_drive = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sPEr342-A2V2"
   },
   "outputs": [],
   "source": [
    "a = final_list_players[0]\n",
    "df = a.T\n",
    "for i in range(1,len(final_list_players)):\n",
    "    lo = final_list_players[i].T\n",
    "    df = pd.concat([df,lo],axis=1)\n",
    "final_df = df.T\n",
    "final_df.to_csv(\"output_players.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zTpdYlfTGnfl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Copy of Copy of Edt_1_Final_push.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Gokul_IndicWiki",
   "language": "python",
   "name": "gokul_indicwiki"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
